{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T00:10:53.941397Z",
     "start_time": "2019-01-09T00:10:53.932531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T00:10:54.931870Z",
     "start_time": "2019-01-09T00:10:54.903207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on January 6 2018\\n@author: Neven Caplar\\n@contact: ncaplar@princeton.edu\\n\\nProject by Sandro Tacchella (CfA) and Neven Caplar (PU)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Created on January 6 2018\n",
    "@author: Neven Caplar\n",
    "@contact: ncaplar@princeton.edu\n",
    "\n",
    "Project by Sandro Tacchella (CfA) and Neven Caplar (PU)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T00:10:56.530568Z",
     "start_time": "2019-01-09T00:10:56.524942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "try {\n",
       "  require(['base/js/utils'], function (utils) {\n",
       "    utils.load_extension('code_prettify/code_prettify');\n",
       "    utils.load_extension('collapsible_headings/main'); \n",
       "    utils.load_extension('codefolding/edit'); \n",
       "    utils.load_extension('codefolding/main'); \n",
       "    utils.load_extension('execute_time/ExecuteTime');   \n",
       "    utils.load_extension('toc2/main'); \n",
       "  });\n",
       "}\n",
       "catch (err) {\n",
       "  console.log('toc2 load error:', err);\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "try {\n",
    "  require(['base/js/utils'], function (utils) {\n",
    "    utils.load_extension('code_prettify/code_prettify');\n",
    "    utils.load_extension('collapsible_headings/main'); \n",
    "    utils.load_extension('codefolding/edit'); \n",
    "    utils.load_extension('codefolding/main'); \n",
    "    utils.load_extension('execute_time/ExecuteTime');   \n",
    "    utils.load_extension('toc2/main'); \n",
    "  });\n",
    "}\n",
    "catch (err) {\n",
    "  console.log('toc2 load error:', err);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T22:12:50.195192Z",
     "start_time": "2019-01-09T22:12:50.184095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make notebook nice and wide to fill the entire screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T20:20:40.071965Z",
     "start_time": "2019-01-27T20:20:40.047856Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#https://github.com/andycasey/ads\n",
    "import ads\n",
    "ads.config.token = 'kG2dNKUfa9H6QRqT00CsJYhHkfFz0uqzSx8JorPK'\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T22:23:13.410302Z",
     "start_time": "2019-01-09T22:23:13.395211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IapetusUSA'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import socket\n",
    "socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plan\n",
    "\n",
    "1. Get all first authors from the 2003-2008 from A&A, APJ, MNRAS, SCI, Nature\n",
    "2. Find all authors for which we can identify their names\n",
    "3. Query according to the names\n",
    "4. Deduce if there is possible confusion\n",
    "5. If not if they have left the field - if yes, when\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all first authors from the 2003-2008 from A&A, APJ, MNRAS, SCI, Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T22:54:47.878922Z",
     "start_time": "2019-01-09T22:54:43.856640Z"
    }
   },
   "outputs": [],
   "source": [
    "#os.chdir('/Users/nevencaplar/Documents/Gender/')\n",
    "#with open('Master_Table.pickle', 'rb') as handle:\n",
    "#  Master_Table = pickle.load(handle)\n",
    "\n",
    "\n",
    "if socket.gethostname()=='IapetusUSA':\n",
    "    os.chdir('/Users/nevencaplar/Documents/Gender/Gender2019_data/')\n",
    "else:\n",
    "    os.chdir('/home/caplarn/Documents/Astrodataiscool/Gender/MasterTableJuly/')\n",
    "with open('Master_Table.pickle', 'rb') as handle:\n",
    "    # load the Master_Table from our original projects with all the papers\n",
    "    # we use this as a initial sample upon which we base our analysis\n",
    "    Master_Table = pickle.load(handle, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T22:54:47.884965Z",
     "start_time": "2019-01-09T22:54:47.880521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208577"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we look at what is the length of this array \n",
    "# 208577 papers in the whole data\n",
    "len(Master_Table[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T22:54:48.878485Z",
     "start_time": "2019-01-09T22:54:48.873428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003A&A...397....1T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2008Sci...322.1828E'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first paper from 2003\n",
    "print(Master_Table[0][115130])\n",
    "\n",
    "#last paper from 2008\n",
    "Master_Table[0][152154]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T22:54:55.986485Z",
     "start_time": "2019-01-09T22:54:55.967521Z"
    }
   },
   "outputs": [],
   "source": [
    "# this gives list of all identifiers for all of the papers from 2003-2008\n",
    "list_of_identifiers_03_08=Master_Table[0][115130:152154+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T23:14:05.093532Z",
     "start_time": "2019-01-09T23:14:05.089631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37025"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the number of papers in those years\n",
    "len(list_of_identifiers_03_08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  First stage - got first 4987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T18:23:40.248963Z",
     "start_time": "2019-01-10T16:59:14.589016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [25:24:25<00:00, 18.29s/it]   \n"
     ]
    }
   ],
   "source": [
    "# query ads for these papers\n",
    "# at the moment just testing with 5000 papers\n",
    "# 18 seconds sleep assures that you do not break ads limit and we get only 5000 papers every day\n",
    "articles=[]\n",
    "for bibcode in tqdm(list_of_identifiers_03_08[0:5000]):\n",
    "    time.sleep(18) \n",
    "    try:\n",
    "        articles.append(list(ads.SearchQuery(bibcode=bibcode))[0])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T19:48:58.243208Z",
     "start_time": "2019-01-27T19:48:57.132835Z"
    }
   },
   "outputs": [],
   "source": [
    "# export the data\n",
    "import pickle\n",
    "with open('/Users/nevencaplar/Documents/Gender/Gender2019_data/' + 'articles_I.pkl', 'wb') as f:\n",
    "    pickle.dump(articles,f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T19:49:08.560070Z",
     "start_time": "2019-01-27T19:48:59.486418Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "with open('/Users/nevencaplar/Documents/Gender/Gender2019_data/articles_I.pkl', 'rb') as f:\n",
    "    articles=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T20:42:20.272482Z",
     "start_time": "2019-02-03T20:42:20.265281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4987"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying papers via author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of all first authors\n",
    "list_of_first_author=[]\n",
    "for i in range(len(articles)):\n",
    "    list_of_first_author.append(articles[i].first_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First stage - Feb 3 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T21:09:11.727599Z",
     "start_time": "2019-02-03T20:55:19.576624Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [13:52<00:00,  4.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# get first 4000\n",
    "list_of_papers=[]\n",
    "for l in tqdm(range(0,4000)):\n",
    "    papers = list(ads.SearchQuery(author=list_of_first_author[list_of_first_author_index]))\n",
    "    list_of_papers.append(papers)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T21:09:13.696293Z",
     "start_time": "2019-02-03T21:09:11.729815Z"
    }
   },
   "outputs": [],
   "source": [
    "# export the data\n",
    "import pickle\n",
    "with open('/Users/nevencaplar/Documents/Gender/Gender2019_data/' + 'articles_via_author_I.pkl', 'wb') as f:\n",
    "    pickle.dump(list_of_papers,f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find papers by a single author and see if you can identify the name uniquely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building the master function, step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T19:56:25.554583Z",
     "start_time": "2019-01-27T19:56:25.544384Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T20:39:41.424606Z",
     "start_time": "2019-02-03T20:39:41.197040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chiaberge'"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets all the papers for one first author in the list_of_first_author\n",
    "list_of_first_author_index=2000\n",
    "\n",
    "papers = list(ads.SearchQuery(author=list_of_first_author[list_of_first_author_index]))\n",
    "\n",
    "surname_of_the_first_author=list_of_first_author[list_of_first_author_index].split(\",\",1)[0]\n",
    "surname_of_the_first_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T20:39:42.665736Z",
     "start_time": "2019-02-03T20:39:42.660236Z"
    }
   },
   "outputs": [],
   "source": [
    "# create array contaning all papers by this author\n",
    "list_of_papers_for_one_author=[]\n",
    "for i in range(len(papers)):\n",
    "    list_of_papers_for_one_author.append(papers[i].author)\n",
    "    \n",
    "array_of_papers_for_one_author=np.array(list_of_papers_for_one_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T20:39:45.301289Z",
     "start_time": "2019-02-03T20:39:45.284930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco',\n",
       " 'Chiaberge, Marco']"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the names associated with the original first author\n",
    "papers[-1].author\n",
    "list_of_author_names=[]\n",
    "for j in range(len(papers)):\n",
    "    try:\n",
    "        # find position in the author list of each paper where the original first author is\n",
    "        index_for_single_paper_saying_where_author_is = [i for i, x in enumerate(papers[j].author) if surname_of_the_first_author in x ]\n",
    "        # append the found name\n",
    "        list_of_author_names.append(papers[j].author[index_for_single_paper_saying_where_author_is[0]])\n",
    "    # IndexError occurs when we can not find the surname of the authors in the authors list\n",
    "    # this is most often due to different spelling of the name\n",
    "    except IndexError:\n",
    "        print([j,False])\n",
    "        \n",
    "        \n",
    "# check\n",
    "list_of_author_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T19:48:10.627725Z",
     "start_time": "2019-02-03T19:48:10.620934Z"
    }
   },
   "outputs": [],
   "source": [
    "# find all the first names that are associated with this author query\n",
    "list_of_given_names_for_a_single_surname_search=[]\n",
    "for l in range(len(list_of_author_names)):\n",
    "    try:\n",
    "        list_of_given_names_for_a_single_surname_search.append(list_of_author_names[l].split(\",\",1)[1])\n",
    "    # fail will occurs if there is no comma in the name, so we can not identify the first name of the author\n",
    "    except IndexError:\n",
    "        print([l,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T19:56:45.532293Z",
     "start_time": "2019-02-03T19:56:45.502169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "list_of_given_names_for_a_single_surname_search_without_short=[]\n",
    "# remove all the names shorter or equal to 3 characters\n",
    "# have to think if this ok\n",
    "for m in range(len(list_of_given_names_for_a_single_surname_search)):\n",
    "    if len(list_of_given_names_for_a_single_surname_search[m])<=3:\n",
    "        pass\n",
    "    else:\n",
    "        list_of_given_names_for_a_single_surname_search_without_short.append(str.split(str.strip(list_of_given_names_for_a_single_surname_search[m])))\n",
    "        \n",
    "    array_of_given_names_for_a_single_surname_search_without_short=np.array(list_of_given_names_for_a_single_surname_search_without_short)\n",
    "\n",
    "    # create 2 arrays\n",
    "    # one has only initials\n",
    "    # one has full names\n",
    "\n",
    "    array_of_given_names_for_a_single_surname_search_without_short_only_initials=[]\n",
    "    array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names=[]\n",
    "    for i in range(len(array_of_given_names_for_a_single_surname_search_without_short)):\n",
    "        array_of_given_names_for_a_single_surname_search_without_short_only_initials.append(array_of_given_names_for_a_single_surname_search_without_short[i][0][0])\n",
    "        if len(array_of_given_names_for_a_single_surname_search_without_short[i][0])>=3:\n",
    "            array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names.append(array_of_given_names_for_a_single_surname_search_without_short[i][0]) \n",
    "    \n",
    "    # check if all the first names are the same for this author query\n",
    "    # we demand that\n",
    "    # there are full names (length of array larger than 0)\n",
    "    # all full names are the same\n",
    "    # all initials are the same\n",
    "    if len(array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names)>2:\n",
    "        print(all_same(array_of_given_names_for_a_single_surname_search_without_short_only_initials))\n",
    "        print(all_same(array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names))\n",
    "    else:\n",
    "        print('there are no full names avaliable')\n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working with master function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T20:36:17.455307Z",
     "start_time": "2019-02-03T20:36:17.284436Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def all_same(items):\n",
    "    return all(x == items[0] for x in items)\n",
    "\n",
    "def unique_authors_and_their_papers(list_of_first_author_index):\n",
    "    # !need to change to that it takes prepared list_of_papers!\n",
    "    # commented on Feb 3\n",
    "    \n",
    "    #papers = list(ads.SearchQuery(author=list_of_first_author[list_of_first_author_index]))\n",
    "    #surname_of_the_first_author=list_of_first_author[list_of_first_author_index].split(\",\",1)[0]\n",
    "    \n",
    "    # create array contaning all papers by this author\n",
    "    list_of_papers_for_one_author=[]\n",
    "    for i in range(len(papers)):\n",
    "        list_of_papers_for_one_author.append(papers[i].author)\n",
    "\n",
    "    array_of_papers_for_one_author=np.array(list_of_papers_for_one_author)\n",
    "\n",
    "    papers[-1].author\n",
    "    list_of_author_names=[]\n",
    "    for j in range(len(papers)):\n",
    "        try:\n",
    "            # find position in the author list of each paper where the original first author is\n",
    "            index_for_single_paper_saying_where_author_is = [i for i, x in enumerate(papers[j].author) if surname_of_the_first_author in x ]\n",
    "            # append the found name\n",
    "            list_of_author_names.append(papers[j].author[index_for_single_paper_saying_where_author_is[0]])\n",
    "        # IndexError occurs when we can not find the surname of the authors in the authors list\n",
    "        # this is most often due to different spelling of the name\n",
    "        except IndexError:\n",
    "            print('can not find surname')\n",
    "            print([j,False])\n",
    "\n",
    "    # find all the first names that are associated with this author query\n",
    "    list_of_given_names_for_a_single_surname_search=[]\n",
    "    for l in range(len(list_of_author_names)):\n",
    "        try:\n",
    "            list_of_given_names_for_a_single_surname_search.append(list_of_author_names[l].split(\",\",1)[1])\n",
    "        # fail will occurs if there is no comma in the name, so we can not identify the first name of the author\n",
    "        except IndexError:\n",
    "            print ('no comma in the author list')\n",
    "            print([l,False])\n",
    "            \n",
    "    list_of_given_names_for_a_single_surname_search_without_short=[]\n",
    "    # remove all the names shorter or equal to 3 characters\n",
    "    # have to think if this ok\n",
    "    for m in range(len(list_of_given_names_for_a_single_surname_search)):\n",
    "        if len(list_of_given_names_for_a_single_surname_search[m])<=3:\n",
    "            pass\n",
    "        else:\n",
    "            list_of_given_names_for_a_single_surname_search_without_short.append(str.split(str.strip(list_of_given_names_for_a_single_surname_search[m])))\n",
    "\n",
    "    array_of_given_names_for_a_single_surname_search_without_short=np.array(list_of_given_names_for_a_single_surname_search_without_short)\n",
    "\n",
    "    # create 2 arrays\n",
    "    # one has only initials\n",
    "    # one has full names\n",
    "\n",
    "    array_of_given_names_for_a_single_surname_search_without_short_only_initials=[]\n",
    "    array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names=[]\n",
    "    for i in range(len(array_of_given_names_for_a_single_surname_search_without_short)):\n",
    "        array_of_given_names_for_a_single_surname_search_without_short_only_initials.append(array_of_given_names_for_a_single_surname_search_without_short[i][0][0])\n",
    "        if len(array_of_given_names_for_a_single_surname_search_without_short[i][0])>=3:\n",
    "            array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names.append(array_of_given_names_for_a_single_surname_search_without_short[i][0]) \n",
    "    \n",
    "    # check if all the first names are the same for this author query\n",
    "    # we demand that\n",
    "    # there are full names (length of array larger than 0)\n",
    "    # all full names are the same\n",
    "    # all initials are the same\n",
    "    if len(array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names)>2:\n",
    "        print(all_same(array_of_given_names_for_a_single_surname_search_without_short_only_initials))\n",
    "        print(all_same(array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names))\n",
    "    else:\n",
    "        print('there are no full names avaliable')\n",
    "        print(False)\n",
    "           \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T20:06:16.689150Z",
     "start_time": "2019-02-03T20:06:16.683511Z"
    }
   },
   "outputs": [],
   "source": [
    "array_of_given_names_for_a_single_surname_search_without_short=np.array(list_of_given_names_for_a_single_surname_search_without_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T20:30:05.431935Z",
     "start_time": "2019-02-03T20:30:05.424476Z"
    }
   },
   "outputs": [],
   "source": [
    "array_of_given_names_for_a_single_surname_search_without_short_only_initials=[]\n",
    "array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names=[]\n",
    "\n",
    "for i in range(len(array_of_given_names_for_a_single_surname_search_without_short)):\n",
    "    array_of_given_names_for_a_single_surname_search_without_short_only_initials.append(array_of_given_names_for_a_single_surname_search_without_short[i][0][0])\n",
    "    if len(array_of_given_names_for_a_single_surname_search_without_short[i][0])>=3:\n",
    "        array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names.append(array_of_given_names_for_a_single_surname_search_without_short[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T20:30:09.443225Z",
     "start_time": "2019-02-03T20:30:09.438215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_of_given_names_for_a_single_surname_search_without_short_only_initials_full_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T20:39:29.434679Z",
     "start_time": "2019-02-03T20:39:25.908652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "unique_authors_and_their_papers(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
